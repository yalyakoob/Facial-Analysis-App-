{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8235a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feea2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection\n",
    "face_detector_model = cv2.dnn.readNetFromCaffe('models/deploy.prototxt.txt',\n",
    "                                               'models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "#feature extraction\n",
    "face_feature_model = cv2.dnn.readNetFromTorch('models/openface.nn4.small2.v1.t7')\n",
    "#face recognition\n",
    "face_recognition_model = pickle.load(open('models/machinelearning_face_person_identity2.pkl',\n",
    "                                         mode='rb'))\n",
    "#emotion recognition model\n",
    "emotion_recognition_model = pickle.load(open('models/machinelearning_face_emotion2.pkl',\n",
    "                                            mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8c0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display/close images\n",
    "def display(winame,image):\n",
    "    cv2.namedWindow(winame)\n",
    "    cv2.imshow(winame,image)\n",
    "    cv2.waitKey(0) #close window when key press is detected\n",
    "    cv2.destroyWindow(winame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b1374e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youssef Al-Yakoob\n",
      "0.39420213319116804\n",
      "happy\n",
      "0.2887989836685445\n"
     ]
    }
   ],
   "source": [
    "#pipeline model test\n",
    "img = cv2.imread('images_2/Youssef Al-Yakoob/IMG_2050.PNG')\n",
    "image = img.copy()\n",
    "h,w = img.shape[:2]\n",
    "#face detection\n",
    "img_blob = cv2.dnn.blobFromImage(image,1,(300,300),(104,177,123),swapRB=False,crop=False)\n",
    "face_detector_model.setInput(img_blob)\n",
    "detections = face_detector_model.forward()\n",
    "\n",
    "if len(detections)>0:\n",
    "    for i, confidence in enumerate(detections[0,0,:,2]):\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "            startx,starty,endx,endy = box.astype(int)\n",
    "            \n",
    "            cv2.rectangle(image,(startx,starty),(endx,endy),(0,255,0))\n",
    "            \n",
    "            #feature extraction\n",
    "            face_roi = img[starty:endy,startx:endx]\n",
    "            face_blob = cv2.dnn.blobFromImage(face_roi,1/255,(96,96),(0,0,0),\n",
    "                                              swapRB=True,crop=True)\n",
    "            face_feature_model.setInput(face_blob)\n",
    "            vectors = face_feature_model.forward()\n",
    "            \n",
    "            #model predictions\n",
    "            #facial recognition\n",
    "            face_name = face_recognition_model.predict(vectors)[0]\n",
    "            face_score = face_recognition_model.predict_proba(vectors).max()\n",
    "            #emotion recognition\n",
    "            emotion_name = emotion_recognition_model.predict(vectors)[0]\n",
    "            emotion_score = emotion_recognition_model.predict_proba(vectors).max()\n",
    "            \n",
    "            print(face_name)\n",
    "            print(face_score)\n",
    "            print(emotion_name)\n",
    "            print(emotion_score)\n",
    "            text_face = '{} : {:.0f}%'.format(face_name,100*face_score)\n",
    "            text_emotion = '{} : {:.0f}%'.format(emotion_name,100*emotion_score)\n",
    "            cv2.putText(image,text_face,(startx,starty),\n",
    "                        cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "            cv2.putText(image,text_emotion,(startx,endy),\n",
    "                        cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "\n",
    "            \n",
    "\n",
    "display('pipeline',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75be731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline function\n",
    "def pipeline_model(path):\n",
    "    img = cv2.imread(path)\n",
    "    image = img.copy()\n",
    "    h,w = img.shape[:2]\n",
    "    #face detection\n",
    "    img_blob = cv2.dnn.blobFromImage(image,1,(300,300),(104,177,123),swapRB=False,crop=False)\n",
    "    face_detector_model.setInput(img_blob)\n",
    "    detections = face_detector_model.forward()\n",
    "    \n",
    "    #machine learning results\n",
    "    machinelearning_results = dict(face_detect_score = [],\n",
    "                                   face_name = [],\n",
    "                                   face_name_score = [],\n",
    "                                   emotion_name = [],\n",
    "                                   emotion_name_score = [],\n",
    "                                   count = [])\n",
    "    count = 1\n",
    "\n",
    "    if len(detections)>0:\n",
    "        for i, confidence in enumerate(detections[0,0,:,2]):\n",
    "            if confidence > 0.5:\n",
    "                box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "                startx,starty,endx,endy = box.astype(int)\n",
    "            \n",
    "                cv2.rectangle(image,(startx,starty),(endx,endy),(0,255,0))\n",
    "            \n",
    "                #feature extraction\n",
    "                face_roi = img[starty:endy,startx:endx]\n",
    "                face_blob = cv2.dnn.blobFromImage(face_roi,1/255,(96,96),(0,0,0),\n",
    "                                                  swapRB=True,crop=True)\n",
    "                face_feature_model.setInput(face_blob)\n",
    "                vectors = face_feature_model.forward()\n",
    "            \n",
    "                #model predictions\n",
    "                #facial recognition\n",
    "                face_name = face_recognition_model.predict(vectors)[0]\n",
    "                face_score = face_recognition_model.predict_proba(vectors).max()\n",
    "                #emotion recognition\n",
    "                emotion_name = emotion_recognition_model.predict(vectors)[0]\n",
    "                emotion_score = emotion_recognition_model.predict_proba(vectors).max()\n",
    "            \n",
    "\n",
    "                text_face = '{} : {:.0f}%'.format(face_name,100*face_score)\n",
    "                text_emotion = '{} : {:.0f}%'.format(emotion_name,100*emotion_score)\n",
    "                cv2.putText(image,text_face,(startx,starty),\n",
    "                            cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                cv2.putText(image,text_emotion,(startx,endy),\n",
    "                            cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                machinelearning_results['count'].append(count)\n",
    "                machinelearning_results['face_detect_score'].append(confidence)\n",
    "                machinelearning_results['face_name'].append(face_name)\n",
    "                machinelearning_results['face_name_score'].append(face_score)\n",
    "                machinelearning_results['emotion_name'].append(emotion_name)\n",
    "                machinelearning_results['emotion_name_score'].append(emotion_score)\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "    return machinelearning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9c1d5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face_detect_score': [0.9973253],\n",
       " 'face_name': ['Youssef Al-Yakoob'],\n",
       " 'face_name_score': [0.39420213319116804],\n",
       " 'emotion_name': ['happy'],\n",
       " 'emotion_name_score': [0.2887989836685445],\n",
       " 'count': [1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pipeline_model('images_2/Youssef Al-Yakoob/IMG_2050.PNG')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ab7a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('pipeline',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffcc9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "tom =pipeline_model('images_2/Tom Curise/tom_cruise_movies.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15064b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('tom',tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76716bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
